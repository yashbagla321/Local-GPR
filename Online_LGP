import numpy as np
import matplotlib.pyplot as plt
import scipy.io
import random




def Online_Learning_LGP(X_train,Y_train,Max_Size,lim,LearnHyp,OnlineTrain,InfoGain):
    global X, Y, C, Nr_Loc, Nr_Update, Nr_Total, KerMat, InvKerMat, H_pred


    ## Initialization
    X = np.zeros(1,1)
    Y = np.zeros(1,1)
    KerMat = np.zeros(1,1)
    InvKerMat = np.zeros(1,1)
    
    H_pred = []
    C = []
    Yh = []
    D = []
    
    Nr_Loc = 0
    Nr_Update = 0
    Nr_Total = 0
    LocIndex = 0
    
    LocDim = 1   
    
    GainLim = 0.01
    
    if (LearnHyp == 1 and OnlineTrain == 0):
    
    
        ## Data for hyper-parameter optimization
        X_Input = X_train
        Y_Input = Y_train
    
        ## Initial values for the hyper-parameters 
        Hyp = [np.ones(1,len(X_Input,2)),1,0.1]
        
        
    
    
        ## Read optimized hyper-parameters
        hyper = scipy.io.loadmat('gpr1-hyper_res.stv')

        H_pred = np.exp(hyper)
    
        ## Save hyper-parameters
    
    elif (OnlineTrain == 1 and LearnHyp == 0):
    
        
            X_in = X_train;
            Y_in = Y_train;
        
            s = len(X_in,1)
            
            for k in range(s):
    
                inc = X_in[k,:]
                inW = X_in[k,1:LocDim]
                tau = Y_in[k]
    
                if (Nr_Loc >= 1):
                
                    for j in range(Nr_Loc):
                        S = (inW - C[j,:])**2*H_pred[0:LocDim]
                        D[j] = np.exp(-0.5*S) 
                    
                    
    
                    ## Finding local models
                    [D,LocIndex] = sorted(D, reverse = True)
                    
                    ## Online-prediction
                    Yh[k] = Pred_LGP(inc,LocIndex(1))
    
                    ## Localization of query point:
                    Local_LGP(inc,tau,lim,LocDim,LocIndex(1),D(1),Max_Size,InfoGain,GainLim)
                    
                else:
                ## generate a new model if no local models are available
                
                    Local_LGP(inc,tau,lim,LocDim,0,0,Max_Size,InfoGain,GainLim)
    
                    # Local Prediction
                    Yh[k] = 0
    
                
            
    
            
            
            ## Plot online prediction results
            plt.plot(Y_in,'*')
            plt.plot(Yh,'--r')
            
    
    else:
            # Error message
        print('Error in Flags')
    
        
    
    
        
                
    return(Yh)
    
    
    
##############################################################
#   Prediction of query points
##############################################################

def Pred_LGP(inc,LocIndex):

    global X, Y, InvKerMat, H_pred
    
    KerVec = np.zeros(1,1)
    
    dim = len((H_pred,1)-2)
    
    ## Calculating Kernel-vector
    SizeNr = len(LocIndex,2)
    for j in range(SizeNr):
        rowNr = len(X[1][LocIndex(j)],1)
        for i in range(rowNr):
            K = (inc-X[1][LocIndex(j)][i,:])**2*H_pred[0:dim]
            KerVec[j][i] = H_pred[dim+1]*np.exp(-0.5*K)
        
    
    
    ## Prediction using local models
    Sum = 0
    for j in range(SizeNr):
        s = len(X[1][LocIndex(j)],1)
        PredVec = InvKerMat[1][LocIndex(j)]*Y[1][LocIndex(j)]
        S = KerVec[j]*PredVec
        Sum = Sum + S
    
    
    
    return(Sum)
    
    
    
################################################################                                           
#   Subfunction for localization of data points       
################################################################


def Local_LGP(inc,tau,lim,LocDim,in_max,h,Max_Size,InGain,GainLim):

    #### Define global variables
    global X, Y, C, Nr_Loc, Nr_Update, Nr_Total
    
    
    if (len(C,1)==0 and h < lim):
    
        # No model available or training point does not fit to any model
        Nr_Loc = Nr_Loc+1
        Nr_Update = Nr_Update+1
        Nr_Total = Nr_Total+1
    
        # new center
        C = [[C], [inc[0:LocDim]]]
    
        X[1]= [[X[1]], [np.zeros(1,1)]]
        Y[1]= [[Y[1]], [np.zeros(1,1)]]
    
        X[1][end] = [[X[1][end]], [inc]]  
        Y[1][end] = [[Y[1][end]], [tau]] 
    
        Compute_Ker(Nr_Loc,inc)
    
    
    else:
    
    
        S = len(X[1][in_max],1)
    
        if (S > Max_Size):
            # And randomly delete another point.
    
            if(InGain == 1):
    
                InfGain = Compute_InfoGain(in_max,inc,tau)
    
                if(InfGain > GainLim):
    
                    # Insert data point to model
    
                    Nr_Update = Nr_Update+1
                    Nr_Total = Nr_Total+1
    
                    a = 1
                    b = S
                    LocMem = a + (b-a)*random.random(1,1)
                    LocMem = floor(LocMem)
    
    
                    X[1][in_max][LocMem,:] = inc
    
                    Y[1][in_max][LocMem] = tau
    
                    Compute_Ker(in_max,inc,LocMem)
    
                
    
            else:
    
                Nr_Update = Nr_Update+1
                Nr_Total = Nr_Total+1
    
                a = 1
                b = S
                LocMem = a + (b-a)*random.random(1,1)
                LocMem = floor(LocMem)
    
    
                X[1][in_max][LocMem,:] = inc
    
                Y[1][in_max][LocMem] = tau
    
                Compute_Ker(in_max,inc,LocMem)
    
            
    
        else:
    
            Nr_Update = Nr_Update + 1
            Nr_Total = Nr_Total + 1

            X[1][in_max] = [[X[1][in_max]], [inc]]
            Y[1][in_max] = [[Y[1][in_max]], [tau]]
    
            Compute_Ker(in_max,inc)
    
        
    
    
    
     
    
    
    
##################################################################
#   Subfunction for computing covariance matrix of local models
##################################################################

def Compute_Ker(modelNr,X_in,ModelInd):
    
    
    global X, Y, KerMat, InvKerMat, H_pred
    
    n = len(Y[1][modelNr],1)
    dim = len(H_pred,1) - 2
    
    if(nargin == 1):
        
        for m in range(n):
    
            X_m = X[0][modelNr][m,:]
            for k in range(1, n):
    
                X_k = X[0][modelNr][k,:]
                # Distance
                D = (X_m-X_k)**2*H_pred[0:dim]
                KerMat[0][modelNr][m,k]= H_pred[dim+1]*np.exp(-0.5*D)
                if (m == k):
                    KerMat[0][modelNr][m,k] = KerMat[0][modelNr][m,k]+H_pred[dim+2]
                
            
        
    
    elif(nargin == 2):
        
        K = []
        for j in range(n):
            K[j] = H_pred[dim+1]*np.exp(-0.5*(X_in-X[0][modelNr][j,:])**2*H_pred[0:dim])
        
        K[end] = K[end]+H_pred[dim+2]
    
        if(n > 1):
            KerMat[1][modelNr] = [[KerMat[1][modelNr]], [K[0:end-1]]]
            KerMat[1][modelNr] = np.transpose([[np.transpose(KerMat[1][modelNr])], [K]])
        else:
            KerMat[1][modelNr][n,n] = K
        
        
    elif(nargin == 3):
    
    
        for j in range(n):
            K = (X_in-X[1][modelNr][j,:])**2*H_pred[0:dim]
            if(j == ModelInd):
                KerMat[1][modelNr][j,j] = H_pred[dim+1]*np.exp(-0.5*K)+H_pred[dim+2]
            else:
                KerMat[1][modelNr][ModelInd,j] = H_pred[dim+1]*np.exp(-0.5*K)
                KerMat[1][modelNr][j,ModelInd] = H_pred[dim+1]*np.exp(-0.5*K)
            
        
    
    else:
    
        print('Error in Inputs')
    
    
    
    InvKerMat[1][modelNr] = inv(KerMat[1][modelNr])
    
    

    
    
##############################################################
#   Subfunction for computing Information Gain
##############################################################

def Compute_InfoGain(modelNr,X_in,Y_in):
    
    global X, Y, InvKerMat, H_pred
    
    
    dim = len(H_pred,1)-2
    
    K = []
    SizeLoc = len(X[1][modelNr],1)
    for j in range(SizeLoc):
        K[j] = H_pred[dim+1]*np.exp(-0.5*(X_in-X[1][modelNr][j,:])**2*H_pred[0:dim])
        
    
    sig = H_pred(dim+2)
    k_star = H_pred(dim+1)+sig
    y_star = Y_in
    
    InvK = InvKerMat[1][modelNr]
    
    alpha = 1/(k_star+sig-K*InvK*np.transpose(K))
    V = [[-alpha*InvK*np.transpose(K)], [alpha]]
    K_star = y_star-(sig/(1+sig*alpha))*np.transpose(V)*[[Y[1][modelNr]], [y_star]]
    
    InfGain = 0.5*(np.log(1+sig*alpha)-sig*alpha/(1+sig*alpha)+(K_star^2/sig)*[K, k_star]*V)
    
    return(InfGain)
